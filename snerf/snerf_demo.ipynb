{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shadow Neural Radiance Fields demonstration notebook\n",
    "This notebook contains the demonstration of how to render plots from a pre-trained S-NeRF model, produced using `snerf/train.py`. It is based on the use of TensorFlow-2.2.0 with a single CUDA-enabled GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from snerf import data_handling\n",
    "from snerf import models\n",
    "from snerf import render\n",
    "from snerf import train\n",
    "from snerf import plots\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "def_dtype = np.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config\n",
    "parser = train.config_parser()\n",
    "args = parser.parse_args('--config configs/068/siren_df2_full_sc_config.txt')\n",
    "arg_dict = vars(args)\n",
    "pprint.pprint(arg_dict)\n",
    "dataset = data_handling.generate_dataset(arg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize the image set used for training the network, as well as the corresponding light and viewing angles for the scene. We also show the Ground Truth DEM of the scene (airborne-lidar based), which is used for evaluation of the altitude estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_images(arg_dict['data.train_id'], dataset['train_imgs'], dataset['train_view_dirs'], dataset['train_light_dirs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_view_light_directions(dataset['train_view_dirs'], dataset['train_light_dirs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_depth_map(dataset['depth_map'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the pre-trained model and show its internal architecture, including the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(f\"models/068/model.npy\", arg_dict)\n",
    "model['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to calculate a global rescale factor for the data set based on the size of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale factor\n",
    "arg_dict['rend.rescale'] = render.calculate_rescale_factor(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can render and plot the various S-NeRF outputs : Color, depth map, sun visibility at surface, and albedo. We verify the relighting capability by performing an interpolation between a low and high solar angle. We also generate a flyover video that shows a mixture of relighting and novel view synthesis (can take time to generate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rend = render.render_dataset(dataset, model, ['rgb', 'depth', 'ret_sun', 'no_shadow'], arg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plots.plot_results(dataset['train_imgs'], dataset['train_focals'], dataset_rend['train_rend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plots.plot_results(dataset['test_imgs'], dataset['test_focals'], dataset_rend['test_rend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.render_vertical_depth_comparison(model, arg_dict, dataset['depth_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwf = [dataset['train_imgs'][0].shape[0], dataset['train_imgs'][0].shape[1], 617000.0/0.3/arg_dict[\"data.image.df\"]]\n",
    "light_start = np.rad2deg(dataset['train_light_dirs'][4][0,0]), np.rad2deg(dataset['train_light_dirs'][4][0,1])\n",
    "light_end = np.rad2deg(dataset['train_light_dirs'][11][0,0]), np.rad2deg(dataset['train_light_dirs'][11][0,1])\n",
    "view_angle=(np.pi, np.pi/2) #Vertical view : elevation = 90 deg, az = 180 deg (north up)\n",
    "\n",
    "rets=['rgb', 'depth', 'sky', 'no_shadow']\n",
    "plots.plot_light_angle_inter(model, arg_dict, hwf, light_start, light_end, view_angle, nplots=5, rets=rets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.render_flyover_video(f\"{arg_dict['out.path']}/\", model, arg_dict, hwf, light_start, light_end, rets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
