{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-view satellite photogrammetry with Neural Radiance Fields (NeRF)\n",
    "The objective of this notebook is to study the application of [Neural Radiance Fields](https://www.matthewtancik.com/nerf) to multi-view satellite photogrammetry. This is done using data from the Track 3 of the [IEEE GRSS Data Fusion Contest](http://www.grss-ieee.org/community/technical-committees/data-fusion/2019-ieee-grss-data-fusion-contest/).\n",
    "\n",
    "In particular, the aim of this notebook is to demonstrate an extension of NeRF called SNeRF (Shadow NeRF) which implicitly models directional lighting effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage.transform import rescale, resize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.measure import marching_cubes_lewiner\n",
    "\n",
    "import data_handling\n",
    "import models\n",
    "import render\n",
    "import train\n",
    "from plots import plot_images, plot_view_light_directions, plot_depth_map\n",
    "\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "def_dtype = np.float32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is best run with a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "This dataset is composed of multi-view images over two cities in USA. The azimuth and elevation angles of the satellite, the geographic location of the image, and the solar angles are provided as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': '../configs/068_config.txt', 'data.image.path': '/home/derksend/snerf_release/stereo_nerf/data/068/JAX_068_df1', 'data.image.df': 8, 'data.image.sd': 0.3, 'data.depth.path': '/home/derksend/snerf_release/stereo_nerf/data/068/JAX_068_df1_dsm.tif', 'data.depth.df': 1, 'data.md.path': '/home/derksend/snerf_release/stereo_nerf/data/068/JAX_068_df1_md.txt', 'data.train_id': ['01', '02', '03', '04', '05', '06', '07', '09', '10', '11', '12', '13', '14', '15', '18', '19'], 'data.test_id': ['20', '22'], 'model.ins.light': True, 'model.ins.views': False, 'model.outs.shad': True, 'model.outs.sky': True, 'model.act': 'sin', 'model.act.sin.w0': 32.0, 'model.sigma.depth': 8, 'model.sigma.width': 100, 'model.sigma.skips': [], 'model.c.depth': 1, 'model.c.width': 50, 'model.shad.depth': 4, 'model.shad.width': 50, 'model.emb.pos': 0, 'model.emb.dir': 1, 'rend.nsamples': 64, 'rend.nimportance': 64, 'rend.mode': 'alt', 'rend.mode.nf.near': 3.0, 'rend.mode.nf.far': 10.0, 'rend.mode.alt.max': 30.0, 'rend.mode.alt.min': -30.0, 'rend.unzoom': True, 'rend.rescale': None, 'train.n_epoch': 10000, 'train.n_rand': 256, 'train.lr.init': 1e-04, 'train.lr.decay': 0.1, 'train.noise.sigma': 10.0, 'train.noise.shad': 1.0, 'train.shad': True, 'train.shad.lambda': 0.05, 'train.shad.df': 1, 'train.shad.custom': 'linear', 'train.shad.custom.bounds.start': [160.0, 40.0], 'train.shad.custom.bounds.end': [100.0, 80.0], 'train.shad.custom.bounds.samp': [30, 1], 'shad.direct': False, 'shad.direct.nsamples': 8, 'out.iplot': 1000, 'out.path': '/home/derksend/snerf_release/stereo_nerf/results/068/', 'gpu': '0'}\n"
     ]
    }
   ],
   "source": [
    "# Read config from file\n",
    "parser = train.config_parser()\n",
    "args = parser.parse_args('--config ../configs/068_config.txt')\n",
    "arg_dict = vars(args)\n",
    "print(arg_dict)\n",
    "\n",
    "dataset = data_handling.generate_dataset(arg_dict)\n",
    "arg_dict['rend.rescale'] = render.calculate_rescale_factor(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot some views of a building with an interesting shape : The Jacksonville UF Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_images(arg_dict['data.train_id'], dataset['train_imgs'], dataset['train_view_dirs'], dataset['train_light_dirs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_view_light_directions(dataset['train_view_dirs'], dataset['train_light_dirs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_depth_map(dataset['depth_map'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  models.generate_model(arg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = snerf_models.load_model(f\"{arg_dict['out.path']}model.npy\", arg_dict)\n",
    "its, train_loss = snerf_plots.parse_train_loss(arg_dict)\n",
    "snerf_plots.plot_train_loss(its, train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_dict['train.shad'] = False\n",
    "arg_dict['train.shad.lambda'] = 0.05\n",
    "# arg_dict['train.shad.df'] = 1\n",
    "# arg_dict['rend.nimportance'] = 0\n",
    "# arg_dict['rend.nsamples'] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training rays\n",
    "train_rays = render.generate_train_rays(dataset, arg_dict)\n",
    "if arg_dict['train.shad']:\n",
    "    sc_train_rays = render.generate_train_light_correction_rays(dataset, arg_dict)\n",
    "    if arg_dict['train.shad.custom'] in ['linear', 'rectangle']:\n",
    "        custom_sc_rays = render.generate_custom_light_correction_rays(dataset, arg_dict)\n",
    "        sc_train_rays = render.concat_rays(sc_train_rays, custom_sc_rays)\n",
    "else:\n",
    "    sc_train_rays = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = train.init_exp_decay_adam(1e-4, 1000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "0 11.593910217285156 0.03413091227412224\n",
      "1 14.110355377197266 0.0356413908302784\n",
      "2 14.238982200622559 0.03246796503663063\n",
      "3 14.488728523254395 0.03257639333605766\n",
      "4 14.663616180419922 0.03240058571100235\n",
      "5 15.320385932922363 0.03386761620640755\n",
      "6 14.781527519226074 0.03275985270738602\n",
      "7 15.734472274780273 0.03188895806670189\n",
      "8 15.28876781463623 0.030201686546206474\n",
      "9 14.815862655639648 0.03031565621495247\n",
      "25 16.14531135559082 0.015308404341340065\n",
      "50 16.4764347076416 0.0036405466962605715\n",
      "75 17.44025993347168 0.002665905514732003\n"
     ]
    }
   ],
   "source": [
    "# N_iterations = arg_dict['train.n_epoch']\n",
    "N_iterations = 100\n",
    "\n",
    "model, train_loss, scores = train.train_model(model, optimizer, N_iterations, arg_dict, train_rays, sc_train_rays=sc_train_rays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snerf_models.save_model(arg_dict['out.path'], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(train_loss[0])\n",
    "train_loss = [line.split(' ') for line in train_loss]\n",
    "its = [int(l[0]) for l in train_loss]\n",
    "rgb_loss = [float(l[1]) for l in train_loss]\n",
    "loss_out = [rgb_loss]\n",
    "if arg_dict['train.shad']:\n",
    "    shad_loss = [float(l[2]) for l in train_loss]\n",
    "    loss_out.append(shad_loss)\n",
    "\n",
    "snerf_plots.plot_train_loss(its, loss_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rend = render.render_dataset(dataset, model, ['rgb', 'depth', 'sky', 'no_shadow'], arg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snerf_plots' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-064e6920549e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnerf_plots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_imgs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_rend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_rend'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'snerf_plots' is not defined"
     ]
    }
   ],
   "source": [
    "snerf_plots.plot_results(dataset['train_imgs'], dataset_rend['train_rend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "snerf_plots.plot_results(dataset['test_imgs'], dataset_rend['test_rend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadir view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_vertical_depth_comparison(model, arg_dict, dsm, dsm_df, thresh=1):\n",
    "    SR = 0.5 * dsm_df\n",
    "    radius = 617000.0/SR\n",
    "    arg_dict_temp = arg_dict.copy()\n",
    "    arg_dict_temp['data.image.sd'] = SR\n",
    "    arg_dict_temp['data.image.df'] = 1\n",
    "    az, el = np.pi, np.pi/2\n",
    "    pose = data_handling.pose_spherical(az, -el, radius)\n",
    "    hwf = dsm.shape[0], dsm.shape[1], radius\n",
    "    light_dir=tf.reshape(tf.convert_to_tensor([np.deg2rad(100), np.deg2rad(80)], dtype=def_dtype), [1,2])\n",
    "    view_dir=tf.reshape(tf.convert_to_tensor([az, el], dtype=def_dtype), [1,2])\n",
    "    ret_dict = snerf_render.render_image(model, arg_dict_temp, hwf, pose, 1.0, light_dir, view_dir, rets=['no_shadow','depth'])\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(ret_dict['no_shadow'])\n",
    "    plt.title('Rendered RGB')\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(121)\n",
    "    disp = ret_dict['depth'] * SR\n",
    "    plt.imshow(disp, vmin=np.min(dsm), vmax=np.max(dsm))\n",
    "    m_e = np.mean(np.abs(disp-dsm))\n",
    "    plt.title(f\"Altitude rendering\\n\"\n",
    "              f\"Average error : {m_e:.4} m\")\n",
    "    plt.colorbar()\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(dsm)\n",
    "    plt.title('Ground truth altitude')\n",
    "    plt.colorbar()\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(121)\n",
    "    a_max = max(arg_dict['rend.mode.alt.max'],  -arg_dict['rend.mode.alt.min'])\n",
    "    plt.imshow(disp-dsm, cmap = 'rainbow', vmin=-20.0, vmax=20.0)\n",
    "    plt.title('Difference between estimated surface altitude and lidar DSM')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(122)\n",
    "    errors = (disp-dsm).numpy().flatten()\n",
    "    plt.hist(errors, bins = 64)\n",
    "    N_good_pixels = np.sum(np.where(np.abs(errors) < thresh, 1, 0))\n",
    "    plt.title(f\"Histogram of altitude errors\\n\"\n",
    "              f\"Pixels with error < {thresh}m : {100*N_good_pixels/hwf[0]/hwf[1]:.3}%\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dsm = dataset['depth_map']\n",
    "print(np.max(dsm))\n",
    "render_vertical_depth_comparison(model, arg_dict, dsm, arg_dict['data.depth.df'], thresh=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hwf = [dataset['train_imgs'][0].shape[0], dataset['train_imgs'][0].shape[1], 617000.0/0.3/arg_dict[\"data.image.df\"]]\n",
    "light_start = [160.0, 33.5]\n",
    "light_end =[114.7, 74.5]\n",
    "view_angle=(np.pi, np.pi/2)\n",
    "snerf_plots.plot_light_angle_inter(model, arg_dict, hwf, light_start, light_end, view_angle, nplots=20, \n",
    "                                   rets=['rgb','depth', 'sky', 'no_shadow'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url_ds=snerf_plots.train_data_video(dataset, arg_dict['out.path'])\n",
    "HTML(f\"\"\"\n",
    "<video width=400 controls autoplay loop>\n",
    "      <source src=\"{data_url_ds}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flyover video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwf = [dataset['train_imgs'][0].shape[0], dataset['train_imgs'][0].shape[1], 617000.0/0.3/arg_dict[\"data.image.df\"]]\n",
    "\n",
    "data_url_f  = snerf_plots.render_flyover_video(arg_dict['out.path'], model, arg_dict, hwf, light_start, light_end, \n",
    "                                               rets=['rgb', 'depth', 'ret_sun', 'no_shadow'])\n",
    "HTML(f\"\"\"\n",
    "<video width=400 controls autoplay loop>\n",
    "      <source src=\"{data_url_f[0]}\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=400 controls autoplay loop>\n",
    "      <source src=\"{data_url_f[1]}\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=400 controls autoplay loop>\n",
    "      <source src=\"{data_url_f[2]}\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=400 controls autoplay loop>\n",
    "      <source src=\"{data_url_f[3]}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = snerf_train.score_overview(snerf_train.test_model(model, dataset, arg_dict), train_loss)\n",
    "print(result_table)\n",
    "result_table = [line.split(',') for line in result_table]\n",
    "display(HTML(tabulate.tabulate(result_table, tablefmt='html')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
